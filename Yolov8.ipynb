{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73244222",
   "metadata": {},
   "source": [
    "## In this notebook we will be using YOLOv8 model from ultralytics to train bone-fracture dataset can be downloaded from Roboflow 100 universe - [here](https://universe.roboflow.com/roboflow-100/bone-fracture-7fylg).\n",
    "\n",
    "\n",
    "#### If you got any suggestions for code improvement or questions. Please reach out."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911feb07",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab216d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import pybboxes as pbx\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.ops import box_convert\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from torchvision.transforms import ToPILImage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d51d9d8",
   "metadata": {},
   "source": [
    "#### Give path to the image directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fef911b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'train/'\n",
    "val_dir = 'val/'\n",
    "test_dir = 'test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f25b74",
   "metadata": {},
   "source": [
    "#### In all the three split data directories you will find json file, which contains information about the image_id, filenames, height, width and other metadata like bboxes, area, category_id etc.\n",
    "\n",
    "#### The make_df function will help us create csv files for the three splits. These will make it easy for us to manipulate the data. Here, we have used list comprehension to make the code look clean and efficient. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4448c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def make_df(modes):\n",
    "    for mode in modes:\n",
    "        with open(f'{mode}/_annotations.coco.json', 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        # Extract information from JSON data\n",
    "        image_ids = [image['id'] for image in data['images']]\n",
    "        file_names = [image['file_name'] for image in data['images']]\n",
    "        heights = [image['height'] for image in data['images']]\n",
    "        widths = [image['width'] for image in data['images']]\n",
    "\n",
    "        annotation_ids = [annot['id'] for annot in data['annotations']]\n",
    "        image_ids_annot = [annot['image_id'] for annot in data['annotations']]\n",
    "        category_ids = [annot['category_id'] for annot in data['annotations']]\n",
    "        bboxes = [annot['bbox'] for annot in data['annotations']]\n",
    "        areas = [annot['area'] for annot in data['annotations']]\n",
    "\n",
    "        # Create pandas dataframe\n",
    "        df = pd.DataFrame({\n",
    "            'image_id': image_ids_annot,\n",
    "            'file_name': [file_names[id] for id in image_ids_annot],\n",
    "            'height': [heights[id] for id in image_ids_annot],\n",
    "            'width': [widths[id] for id in image_ids_annot],\n",
    "            'category_id': category_ids,\n",
    "            'bbox': bboxes,\n",
    "            'area': areas,\n",
    "        })\n",
    "\n",
    "        # Add category names to dataframe\n",
    "        category_names = {category['id']: category['name'] for category in data['categories']}\n",
    "        df['category_name'] = df['category_id'].map(category_names)\n",
    "\n",
    "        # Save dataframe to CSV file\n",
    "        df.to_csv(f'{mode}_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "353ffd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes =['train', 'val', 'test']\n",
    "make_df(modes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c6a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_data.csv')\n",
    "valid = pd.read_csv('valid_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f39521f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>category_id</th>\n",
       "      <th>bbox</th>\n",
       "      <th>area</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70_jpg.rf.a45b1f9b3f335f0cc7210b9dc2f858cf.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>752</td>\n",
       "      <td>4</td>\n",
       "      <td>[242, 211, 125, 175]</td>\n",
       "      <td>21875</td>\n",
       "      <td>messed_up_angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>70_jpg.rf.a45b1f9b3f335f0cc7210b9dc2f858cf.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>752</td>\n",
       "      <td>4</td>\n",
       "      <td>[297, 502, 144, 147]</td>\n",
       "      <td>21168</td>\n",
       "      <td>messed_up_angle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29_jpg.rf.a358d0249bf4ce4ecc85be891f7d1721.jpg</td>\n",
       "      <td>1024</td>\n",
       "      <td>448</td>\n",
       "      <td>2</td>\n",
       "      <td>[243, 618, 27, 27]</td>\n",
       "      <td>729</td>\n",
       "      <td>fracture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>47_jpg.rf.a7792e1d649b43ecabeb2507a006e9ba.jpg</td>\n",
       "      <td>420</td>\n",
       "      <td>348</td>\n",
       "      <td>2</td>\n",
       "      <td>[241, 271, 21, 12]</td>\n",
       "      <td>252</td>\n",
       "      <td>fracture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>166_jpg.rf.aa2a38ccf92bcff3752e3fb5f5fe42ed.jpg</td>\n",
       "      <td>360</td>\n",
       "      <td>360</td>\n",
       "      <td>2</td>\n",
       "      <td>[125, 111, 77, 108]</td>\n",
       "      <td>8316</td>\n",
       "      <td>fracture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                        file_name  height  width  \\\n",
       "0         0   70_jpg.rf.a45b1f9b3f335f0cc7210b9dc2f858cf.jpg    1024    752   \n",
       "1         0   70_jpg.rf.a45b1f9b3f335f0cc7210b9dc2f858cf.jpg    1024    752   \n",
       "2         1   29_jpg.rf.a358d0249bf4ce4ecc85be891f7d1721.jpg    1024    448   \n",
       "3         2   47_jpg.rf.a7792e1d649b43ecabeb2507a006e9ba.jpg     420    348   \n",
       "4         3  166_jpg.rf.aa2a38ccf92bcff3752e3fb5f5fe42ed.jpg     360    360   \n",
       "\n",
       "   category_id                  bbox   area    category_name  \n",
       "0            4  [242, 211, 125, 175]  21875  messed_up_angle  \n",
       "1            4  [297, 502, 144, 147]  21168  messed_up_angle  \n",
       "2            2    [243, 618, 27, 27]    729         fracture  \n",
       "3            2    [241, 271, 21, 12]    252         fracture  \n",
       "4            2   [125, 111, 77, 108]   8316         fracture  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c3395",
   "metadata": {},
   "source": [
    "#### I used a different code to convert the bbox from string format to float numbers and then assigning them to the corresponding x, y, w, h columns made in the dataframe. But this code is short and readable. copied it from kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "109bb07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bbox(df):\n",
    "    bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "    for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "        df[column] = bboxs[:,i]\n",
    "    df.drop(columns=['bbox'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8e67d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess_bbox(train)\n",
    "val_df = preprocess_bbox(valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91f24d",
   "metadata": {},
   "source": [
    "#### Now to convert the csv file to yaml file, which is needed for yolo.  Let's first create a directory to store data. we have to be careful here because yolo reads data from the yaml file, which provides the path to the images and it's labels. Images and labels have to be of the same name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "49491315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make output_dir\n",
    "dest_dir = \"YOLO_DATA\"\n",
    "!mkdir {dest_dir}\n",
    "\n",
    "_ = Path(f\"{dest_dir}/dataset.yaml\").write_text(f\"\"\"path: {dest_dir}\n",
    "train: D:\\\\CODE\\\\Bone fracture\\\\YOLO_DATA\\\\images\\\\train\n",
    "val: D:\\\\CODE\\\\Bone fracture\\\\YOLO_DATA\\\\images\\\\val\n",
    "\n",
    "\n",
    "nc: 4\n",
    "names: ['fracture', 'line', 'messed_up_angle', 'angle']\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa8b83",
   "metadata": {},
   "source": [
    "#### create_txt_file function converts the [x, y, w, h] coco format bboxes to yolo format [xcenter, ycenter, width, height]. \n",
    "#### Note- width and height in yolo format is for the bounding box and all the four values should be normalized between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "37cb6abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_txt_file(path: Path, bboxes, width, height):\n",
    "    \"\"\"Creates a .txt file with annotation strings for the given bounding boxes\"\"\"\n",
    "    \n",
    "    anno_str = []\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
    "        xc = x + w / 2\n",
    "        yc = y + h / 2\n",
    "        xc /= width\n",
    "        yc /= height\n",
    "        w /= width\n",
    "        h /= height\n",
    "        anno_str.append(f\"0 {xc} {yc} {w} {h}\")\n",
    "    path.write_text(\"\\n\".join(anno_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91fc286",
   "metadata": {},
   "source": [
    "#### The below code organizes image and label files into separate directories based on a dataFrame. It iterates over two modes, \"train\" and \"val\", and stores them to their respected mode directories for storing images and labels. It then retrieves relevant information from the dataFrame, such as file names, widths, heights, and bounding box coordinates. The code copies image files to the appropriate directory and creates label files in a specific format. Lastly, it stores the paths of the image and label files in a list called path_list. I found this code to be very efficient and elegant. you can easily modify it for your use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "07c22cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 311/311 [00:00<00:00, 567.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 83/83 [00:00<00:00, 530.57it/s]\n"
     ]
    }
   ],
   "source": [
    "path_list = []\n",
    "for mode in [\"train\", \"val\"]:\n",
    "    image_folder = Path(dest_dir) / \"images\" / f\"{mode}\"\n",
    "    image_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    label_folder = Path(dest_dir) / \"labels\" / f\"{mode}\"\n",
    "    label_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = locals().get(f\"{mode}_df\")\n",
    "\n",
    "    grouped = df.groupby('file_name')\n",
    "    for image_id, group_df in tqdm(grouped, total=len(grouped)):\n",
    "        file_name = group_df.iloc[0].file_name\n",
    "        width, height = group_df.iloc[0].width, group_df.iloc[0].height\n",
    "        bboxes = [(row.x, row.y, row.w, row.h) for _, row in group_df.iterrows()]\n",
    "        img_path = image_folder / f\"{file_name}.jpg\"\n",
    "        label_path = label_folder / f\"{file_name}.txt\"\n",
    "        shutil.copy(f\"{mode}/{file_name}\", img_path)\n",
    "        create_txt_file(label_path, bboxes, width, height)\n",
    "        path_list.append((str(img_path), str(label_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d02bec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2b713b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf400f",
   "metadata": {},
   "source": [
    "#### Careful here while providing the path to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "52e855cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.0.86 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.0.66  Python-3.11.0 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=D:\\CODE\\Bone fracture\\YOLO_DATA\\dataset.yaml, epochs=20, patience=50, batch=8, imgsz=720, save=True, save_period=-1, cache=False, device=0, workers=2, project=None, name=yolov8n_v1_1epoch, exist_ok=False, pretrained=False, optimizer=SGD, verbose=True, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, tracker=botsort.yaml, save_dir=runs\\detect\\yolov8n_v1_1epoch2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.Detect                [4, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011628 parameters, 3011612 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\yolov8n_v1_1epoch2', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "WARNING  imgsz=[720] must be multiple of max stride 32, updating to [736]\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\CODE\\Bone fracture\\YOLO_DATA\\labels\\train.cache... 311 images, 0 backgrounds, 4 corrupt: 100%|██████\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\CODE\\Bone fracture\\YOLO_DATA\\labels\\val.cache... 83 images, 0 backgrounds, 4 corrupt: 100%|██████████|\u001b[0m\n",
      "Plotting labels to runs\\detect\\yolov8n_v1_1epoch2\\labels.jpg... \n",
      "Image sizes 736 train, 736 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\yolov8n_v1_1epoch2\u001b[0m\n",
      "Starting training for 20 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       1/20      1.72G      2.201      3.976      1.686         19        736: 100%|██████████| 39/39 [00:07<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.156     0.0855     0.0562     0.0181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       2/20      1.73G      2.188      3.658      1.641         24        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.205     0.0855     0.0806     0.0233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       3/20      1.73G      2.278      3.585      1.644         17        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:04<0\n",
      "                   all         83        117     0.0716     0.0684     0.0324     0.0122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       4/20      1.73G      2.317      3.588      1.718         21        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117    0.00339      0.256    0.00641    0.00212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       5/20      1.73G      2.372      3.522      1.634         22        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.304       0.12     0.0615     0.0249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       6/20      1.68G      2.328      3.353      1.582         15        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:04<0\n",
      "                   all         83        117      0.231      0.094     0.0675     0.0196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       7/20      1.68G      2.284      3.259      1.605         19        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:04<0\n",
      "                   all         83        117      0.233      0.222      0.102     0.0364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       8/20      1.67G      2.275      3.159      1.624         15        736: 100%|██████████| 39/39 [00:07<00:00,  4.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.137      0.171     0.0687     0.0275\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "       9/20      1.67G      2.235      2.998      1.581         19        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.302      0.197      0.118     0.0436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      10/20      1.66G      2.179      2.999      1.561         29        736: 100%|██████████| 39/39 [00:07<00:00,  5.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.192      0.214      0.106     0.0328\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      11/20      1.67G      2.199      3.294      1.573          8        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:04<0\n",
      "                   all         83        117      0.228      0.214      0.122     0.0514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      12/20      1.67G      2.162      3.156      1.553          9        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.147      0.154     0.0566     0.0201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      13/20      1.68G      2.246       3.19      1.674         11        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.306      0.241      0.215     0.0833\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      14/20      1.68G      2.108      2.932      1.603          8        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.429      0.239       0.21     0.0954\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      15/20      1.66G      2.079      2.865      1.567         11        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.355      0.179      0.186     0.0686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      16/20      1.67G      2.026      2.727      1.517          8        736: 100%|██████████| 39/39 [00:05<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.294      0.231       0.17     0.0645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      17/20      1.68G      1.963      2.647      1.505          8        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.324      0.299      0.225     0.0934\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      18/20      1.66G      1.975      2.608      1.469         10        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.459      0.282      0.251        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      19/20      1.66G      1.951      2.519      1.475          8        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.355      0.308      0.258     0.0975\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      20/20      1.66G      1.928      2.415       1.46          9        736: 100%|██████████| 39/39 [00:06<00:00,  6.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:06<0\n",
      "                   all         83        117      0.408      0.299      0.263      0.104\n",
      "\n",
      "20 epochs completed in 0.128 hours.\n",
      "Optimizer stripped from runs\\detect\\yolov8n_v1_1epoch2\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from runs\\detect\\yolov8n_v1_1epoch2\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating runs\\detect\\yolov8n_v1_1epoch2\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.66  Python-3.11.0 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "Model summary (fused): 168 layers, 3006428 parameters, 0 gradients, 8.1 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 6/6 [00:05<0\n",
      "                   all         83        117      0.404      0.299      0.262      0.104\n",
      "              fracture         83        117      0.404      0.299      0.262      0.104\n",
      "Speed: 1.2ms preprocess, 5.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\yolov8n_v1_1epoch2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Training.\n",
    "\n",
    "results = model.train(\n",
    "   data=\"D:\\\\CODE\\\\Bone fracture\\\\YOLO_DATA\\\\dataset.yaml\",\n",
    "   imgsz=720,\n",
    "   epochs=20,\n",
    "   batch=8,\n",
    "    workers=2,\n",
    "    device='0',\n",
    "   name='yolov8n_v1_1epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2c176a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_paths = glob.glob('runs\\detect\\yolov8n_v1_1epoch2/*jpg') +  glob.glob('runs\\detect\\yolov8n_v1_1epoch2/*png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe119fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for path in result_paths:\n",
    "    image = cv2.imread(path)\n",
    "    plt.figure(figsize=(14,10))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9074ec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = YOLO(\"runs\\detect\\yolov8n_v1_1epoch2\\weights\\\\best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8dde9b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/44 D:\\CODE\\Bone fracture\\test\\105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg: 736x448 3 fractures, 43.1ms\n",
      "image 2/44 D:\\CODE\\Bone fracture\\test\\10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg: 736x736 8 fractures, 75.5ms\n",
      "image 3/44 D:\\CODE\\Bone fracture\\test\\117_jpg.rf.119dccd2483b04d8d3a8c33a1393d362.jpg: 736x256 4 fractures, 22.6ms\n",
      "image 4/44 D:\\CODE\\Bone fracture\\test\\118_jpg.rf.acee2a86eba65adc57f3b15d5acab93c.jpg: 736x288 (no detections), 20.9ms\n",
      "image 5/44 D:\\CODE\\Bone fracture\\test\\11_jpg.rf.8e1c22ba2779121f3ba0a8ae03a20407.jpg: 736x448 1 fracture, 10.1ms\n",
      "image 6/44 D:\\CODE\\Bone fracture\\test\\124_jpg.rf.100aeaede7a9c017d7f74f73cfcf34d7.jpg: 736x608 (no detections), 10.5ms\n",
      "image 7/44 D:\\CODE\\Bone fracture\\test\\124_jpg.rf.dab4a5f6292af8332da8f9bad9751ba6.jpg: 736x256 1 fracture, 9.6ms\n",
      "image 8/44 D:\\CODE\\Bone fracture\\test\\12_jpg.rf.3e4b2f52016c100e9f869397933ef2d3.jpg: 736x224 (no detections), 10.1ms\n",
      "image 9/44 D:\\CODE\\Bone fracture\\test\\131_jpg.rf.1a70e4c9e91ea953aa55988ab20fa95a.jpg: 736x352 1 fracture, 10.6ms\n",
      "image 10/44 D:\\CODE\\Bone fracture\\test\\135_jpg.rf.a8cbe93a3de035a4927b20c42604ae4c.jpg: 736x704 1 fracture, 10.6ms\n",
      "image 11/44 D:\\CODE\\Bone fracture\\test\\145_jpg.rf.5a3d6fbf3dcb9d88626ba82182f29254.jpg: 736x576 6 fractures, 10.5ms\n",
      "image 12/44 D:\\CODE\\Bone fracture\\test\\164_jpg.rf.9a5230f67ddc2426d52597a70c6984f9.jpg: 736x608 2 fractures, 10.6ms\n",
      "image 13/44 D:\\CODE\\Bone fracture\\test\\165_jpg.rf.e831420b761a317ab9fb725e12781bd8.jpg: 736x576 2 fractures, 10.7ms\n",
      "image 14/44 D:\\CODE\\Bone fracture\\test\\16_jpg.rf.0ef960d157f3f332421d9d5a8248a00f.jpg: 736x672 2 fractures, 10.6ms\n",
      "image 15/44 D:\\CODE\\Bone fracture\\test\\173_jpg.rf.7bcde8912d29eb7f5409d79c922924cd.jpg: 736x672 1 fracture, 8.6ms\n",
      "image 16/44 D:\\CODE\\Bone fracture\\test\\186_jpg.rf.3d96cc9db76cb67ec0bab598d4208152.jpg: 544x736 3 fractures, 10.5ms\n",
      "image 17/44 D:\\CODE\\Bone fracture\\test\\194_jpg.rf.b8e95cf106dfe177aa13ff892562c641.jpg: 736x640 (no detections), 10.2ms\n",
      "image 18/44 D:\\CODE\\Bone fracture\\test\\201_jpg.rf.6c78e7e06349770df39f8f8a01a06908.jpg: 736x256 2 fractures, 10.6ms\n",
      "image 19/44 D:\\CODE\\Bone fracture\\test\\202_jpg.rf.896abd97885d07442a74be88a00c73e2.jpg: 736x384 4 fractures, 9.6ms\n",
      "image 20/44 D:\\CODE\\Bone fracture\\test\\204_jpg.rf.3c47ac3c43fab1b4d62a19ceed8c8231.jpg: 736x320 3 fractures, 10.1ms\n",
      "image 21/44 D:\\CODE\\Bone fracture\\test\\205_jpg.rf.b30bdf73b6009d15a54011fd1acab0d0.jpg: 576x736 6 fractures, 10.6ms\n",
      "image 22/44 D:\\CODE\\Bone fracture\\test\\206_jpg.rf.3854aa9bcfdf9e6321ef94c5584f51ab.jpg: 736x384 2 fractures, 9.6ms\n",
      "image 23/44 D:\\CODE\\Bone fracture\\test\\208_jpg.rf.11baac82fd392341802eabf670ade349.jpg: 736x416 (no detections), 10.6ms\n",
      "image 24/44 D:\\CODE\\Bone fracture\\test\\212_jpg.rf.24251e3e1177eae5ca265eac655a799f.jpg: 736x288 (no detections), 10.6ms\n",
      "image 25/44 D:\\CODE\\Bone fracture\\test\\239_jpg.rf.a3c439a0dc2f4c4e5db8b3a4c4a2180c.jpg: 736x736 8 fractures, 9.6ms\n",
      "image 26/44 D:\\CODE\\Bone fracture\\test\\240_jpg.rf.0381da28fab54a07483b6f975dba4959.jpg: 736x256 (no detections), 9.7ms\n",
      "image 27/44 D:\\CODE\\Bone fracture\\test\\242_jpg.rf.55a6cd9175204fcbc9516c8384ad1770.jpg: 736x736 2 fractures, 9.5ms\n",
      "image 28/44 D:\\CODE\\Bone fracture\\test\\258_jpg.rf.6c03add472168dc8aecab04803072d87.jpg: 736x448 1 fracture, 10.0ms\n",
      "image 29/44 D:\\CODE\\Bone fracture\\test\\27_jpg.rf.671159daf1e92be6319d22d4c7c88c80.jpg: 736x672 2 fractures, 10.5ms\n",
      "image 30/44 D:\\CODE\\Bone fracture\\test\\28_jpg.rf.be603dcb6457f3d4d72ef38cc955ab9b.jpg: 736x704 4 fractures, 9.7ms\n",
      "image 31/44 D:\\CODE\\Bone fracture\\test\\28_jpg.rf.e94435d98cb556f0a56cff1d7dd9b920.jpg: 736x352 1 fracture, 9.5ms\n",
      "image 32/44 D:\\CODE\\Bone fracture\\test\\29_jpg.rf.7cfb0432c199bf6e76f661a83a3ca1d7.jpg: 736x736 2 fractures, 9.5ms\n",
      "image 33/44 D:\\CODE\\Bone fracture\\test\\31_jpg.rf.887c2f4daf5684fd355b6574d2eca7aa.jpg: 704x736 3 fractures, 10.6ms\n",
      "image 34/44 D:\\CODE\\Bone fracture\\test\\39_jpg.rf.6c48cc7bc08ea196365cece9cd971749.jpg: 736x576 3 fractures, 10.6ms\n",
      "image 35/44 D:\\CODE\\Bone fracture\\test\\44_jpg.rf.a8f296b8d749e394876fb6979c16caee.jpg: 736x480 2 fractures, 10.5ms\n",
      "image 36/44 D:\\CODE\\Bone fracture\\test\\50_jpg.rf.42e8ad065f5b065703c9f263be40fe8e.jpg: 736x448 1 fracture, 9.7ms\n",
      "image 37/44 D:\\CODE\\Bone fracture\\test\\53_jpg.rf.9eae9dccc03d7b64f61d739e9f4f52f2.jpg: 736x480 2 fractures, 9.6ms\n",
      "image 38/44 D:\\CODE\\Bone fracture\\test\\54_jpg.rf.f8b4216afc0c231f67e05f6afe265886.jpg: 736x640 2 fractures, 10.6ms\n",
      "image 39/44 D:\\CODE\\Bone fracture\\test\\61_jpg.rf.83c119624acc721b292a47934264a533.jpg: 736x736 (no detections), 9.5ms\n",
      "image 40/44 D:\\CODE\\Bone fracture\\test\\69_jpg.rf.daf08f6efb908d9967c2233f1c77ed78.jpg: 736x576 3 fractures, 10.5ms\n",
      "image 41/44 D:\\CODE\\Bone fracture\\test\\72_jpg.rf.60268e8fdd7719031d78a73b5dcdd38f.jpg: 736x608 2 fractures, 10.6ms\n",
      "image 42/44 D:\\CODE\\Bone fracture\\test\\7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg: 736x704 3 fractures, 10.6ms\n",
      "image 43/44 D:\\CODE\\Bone fracture\\test\\90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg: 672x736 2 fractures, 9.6ms\n",
      "image 44/44 D:\\CODE\\Bone fracture\\test\\99_jpg.rf.65fbaae25e71535d041bcd972b4be3a6.jpg: 736x736 1 fracture, 9.1ms\n",
      "Speed: 0.6ms preprocess, 12.9ms inference, 2.2ms postprocess per image at shape (1, 3, 736, 736)\n"
     ]
    }
   ],
   "source": [
    "preds = model_best.predict(conf = 0.1, source = \"D:\\\\CODE\\\\Bone fracture\\\\test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0276938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_sort = os.listdir(test_dir)\n",
    "#test_images_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "08eeb419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>confidence</th>\n",
       "      <th>class</th>\n",
       "      <th>file_name</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>232.354324</td>\n",
       "      <td>637.304871</td>\n",
       "      <td>333.971039</td>\n",
       "      <td>689.682983</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206.505142</td>\n",
       "      <td>607.038513</td>\n",
       "      <td>341.276001</td>\n",
       "      <td>687.368530</td>\n",
       "      <td>0.196243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>259.868469</td>\n",
       "      <td>639.646118</td>\n",
       "      <td>331.049011</td>\n",
       "      <td>688.943665</td>\n",
       "      <td>0.152937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>495.719452</td>\n",
       "      <td>589.294250</td>\n",
       "      <td>546.936829</td>\n",
       "      <td>624.827698</td>\n",
       "      <td>0.259377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>494.625183</td>\n",
       "      <td>554.118103</td>\n",
       "      <td>623.516663</td>\n",
       "      <td>630.272034</td>\n",
       "      <td>0.222910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>529.039185</td>\n",
       "      <td>486.478180</td>\n",
       "      <td>563.995667</td>\n",
       "      <td>524.549683</td>\n",
       "      <td>0.143871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>441.089935</td>\n",
       "      <td>399.950317</td>\n",
       "      <td>512.693970</td>\n",
       "      <td>465.411102</td>\n",
       "      <td>0.101195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.165855</td>\n",
       "      <td>163.834335</td>\n",
       "      <td>108.210091</td>\n",
       "      <td>190.455505</td>\n",
       "      <td>0.118584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.596741</td>\n",
       "      <td>159.201080</td>\n",
       "      <td>112.293900</td>\n",
       "      <td>191.270416</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>366.798584</td>\n",
       "      <td>619.658020</td>\n",
       "      <td>578.528381</td>\n",
       "      <td>983.631897</td>\n",
       "      <td>0.103055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99_jpg.rf.65fbaae25e71535d041bcd972b4be3a6.jpg</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x           y           w           h  confidence  class  \\\n",
       "0   232.354324  637.304871  333.971039  689.682983    0.200192    0.0   \n",
       "1   206.505142  607.038513  341.276001  687.368530    0.196243    0.0   \n",
       "2   259.868469  639.646118  331.049011  688.943665    0.152937    0.0   \n",
       "0   495.719452  589.294250  546.936829  624.827698    0.259377    0.0   \n",
       "1   494.625183  554.118103  623.516663  630.272034    0.222910    0.0   \n",
       "..         ...         ...         ...         ...         ...    ...   \n",
       "1   529.039185  486.478180  563.995667  524.549683    0.143871    0.0   \n",
       "2   441.089935  399.950317  512.693970  465.411102    0.101195    0.0   \n",
       "0    84.165855  163.834335  108.210091  190.455505    0.118584    0.0   \n",
       "1    83.596741  159.201080  112.293900  191.270416    0.117746    0.0   \n",
       "0   366.798584  619.658020  578.528381  983.631897    0.103055    0.0   \n",
       "\n",
       "                                          file_name     i  \n",
       "0   105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg   0.0  \n",
       "1   105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg   0.0  \n",
       "2   105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg   0.0  \n",
       "0    10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg   1.0  \n",
       "1    10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg   1.0  \n",
       "..                                              ...   ...  \n",
       "1     7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg  41.0  \n",
       "2     7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg  41.0  \n",
       "0    90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg  42.0  \n",
       "1    90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg  42.0  \n",
       "0    99_jpg.rf.65fbaae25e71535d041bcd972b4be3a6.jpg  43.0  \n",
       "\n",
       "[96 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_preds = pd.DataFrame(columns=range(6))\n",
    "for i in range(len(preds)):\n",
    "    arri = pd.DataFrame(preds[i].boxes.boxes.cpu()).astype(float)\n",
    "    path = test_images_sort[i]\n",
    "    file = path.split('/')[-1]\n",
    "    arri = arri.assign(file=file)\n",
    "    arri = arri.assign(i=i)\n",
    "    test_preds = pd.concat([test_preds,arri],axis=0)\n",
    "test_preds.columns = ['x','y','w','h','confidence','class','file_name','i']\n",
    "display(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "17511f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = test_preds[[\"file_name\",\"x\",\"y\",\"w\",\"h\",\"confidence\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5b9d18e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg</td>\n",
       "      <td>232.354324</td>\n",
       "      <td>637.304871</td>\n",
       "      <td>333.971039</td>\n",
       "      <td>689.682983</td>\n",
       "      <td>0.200192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg</td>\n",
       "      <td>206.505142</td>\n",
       "      <td>607.038513</td>\n",
       "      <td>341.276001</td>\n",
       "      <td>687.368530</td>\n",
       "      <td>0.196243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg</td>\n",
       "      <td>259.868469</td>\n",
       "      <td>639.646118</td>\n",
       "      <td>331.049011</td>\n",
       "      <td>688.943665</td>\n",
       "      <td>0.152937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg</td>\n",
       "      <td>495.719452</td>\n",
       "      <td>589.294250</td>\n",
       "      <td>546.936829</td>\n",
       "      <td>624.827698</td>\n",
       "      <td>0.259377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg</td>\n",
       "      <td>494.625183</td>\n",
       "      <td>554.118103</td>\n",
       "      <td>623.516663</td>\n",
       "      <td>630.272034</td>\n",
       "      <td>0.222910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg</td>\n",
       "      <td>529.039185</td>\n",
       "      <td>486.478180</td>\n",
       "      <td>563.995667</td>\n",
       "      <td>524.549683</td>\n",
       "      <td>0.143871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg</td>\n",
       "      <td>441.089935</td>\n",
       "      <td>399.950317</td>\n",
       "      <td>512.693970</td>\n",
       "      <td>465.411102</td>\n",
       "      <td>0.101195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg</td>\n",
       "      <td>84.165855</td>\n",
       "      <td>163.834335</td>\n",
       "      <td>108.210091</td>\n",
       "      <td>190.455505</td>\n",
       "      <td>0.118584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg</td>\n",
       "      <td>83.596741</td>\n",
       "      <td>159.201080</td>\n",
       "      <td>112.293900</td>\n",
       "      <td>191.270416</td>\n",
       "      <td>0.117746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>99_jpg.rf.65fbaae25e71535d041bcd972b4be3a6.jpg</td>\n",
       "      <td>366.798584</td>\n",
       "      <td>619.658020</td>\n",
       "      <td>578.528381</td>\n",
       "      <td>983.631897</td>\n",
       "      <td>0.103055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_name           x           y  \\\n",
       "0   105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg  232.354324  637.304871   \n",
       "1   105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg  206.505142  607.038513   \n",
       "2   105_jpg.rf.3cde2fcd15a9bdf6a2d2d32aff48f33d.jpg  259.868469  639.646118   \n",
       "3    10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg  495.719452  589.294250   \n",
       "4    10_jpg.rf.d362a00f9a6b4ac31668dc8aae9c71de.jpg  494.625183  554.118103   \n",
       "..                                              ...         ...         ...   \n",
       "91    7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg  529.039185  486.478180   \n",
       "92    7_jpg.rf.5b79fa048d8e493e13436fdae01bae0c.jpg  441.089935  399.950317   \n",
       "93   90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg   84.165855  163.834335   \n",
       "94   90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg   83.596741  159.201080   \n",
       "95   99_jpg.rf.65fbaae25e71535d041bcd972b4be3a6.jpg  366.798584  619.658020   \n",
       "\n",
       "             w           h  confidence  \n",
       "0   333.971039  689.682983    0.200192  \n",
       "1   341.276001  687.368530    0.196243  \n",
       "2   331.049011  688.943665    0.152937  \n",
       "3   546.936829  624.827698    0.259377  \n",
       "4   623.516663  630.272034    0.222910  \n",
       "..         ...         ...         ...  \n",
       "91  563.995667  524.549683    0.143871  \n",
       "92  512.693970  465.411102    0.101195  \n",
       "93  108.210091  190.455505    0.118584  \n",
       "94  112.293900  191.270416    0.117746  \n",
       "95  578.528381  983.631897    0.103055  \n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16ea0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img_path):\n",
    "\n",
    "    image = os.path.join(f'{test_dir}/{img_path}')\n",
    "    img = cv2.imread(image)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.imshow(img)\n",
    "    \n",
    "    rows = test_preds[test_preds['file_name'] == img_path]\n",
    "    bboxes = []\n",
    "    for _,row in rows.iterrows():\n",
    "        bboxes.append((row.x, row.y, row.w, row.h))\n",
    "    for bbox in bboxes:\n",
    "        rect = patches.Rectangle((bbox[0],bbox[1]),bbox[2],bbox[3],linewidth=1,edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display_img('90_jpg.rf.7163e0a2586c369f8cb72f1cdc305d52.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e957f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
